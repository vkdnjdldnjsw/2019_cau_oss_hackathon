{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "assigment2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOlSAbrp4BfAiPFGn+HUQsu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vkdnjdldnjsw/2019_cau_oss_hackathon/blob/master/assigment/02/assigment2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HobH9Z5mixlh",
        "colab_type": "text"
      },
      "source": [
        "# Linear Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jD68gYsqcQlG",
        "colab_type": "text"
      },
      "source": [
        "* Data\n",
        "\n",
        "  - generate a set of $m$ point pairs $\\{(x^{(i)},y^{(i)})\\}_{i = 1}^m$ from random perturbations using `random` function based on a linear function that you define\n",
        "  - $\\hat{y} = a x + b$ where $a, b \\in \\mathbb{R}$\n",
        "  - $y = \\hat{y} + n$ where $n \\sim \\mathcal{N}(0, \\sigma)$ is drawn from the normal distribution with mean $0$ and standard devication $\\sigma$\n",
        "  - you can choose $m, a, b$ and $\\sigma > 0$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGt50gPFj_Xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "m = 10\n",
        "a = np.random.random() * 10\n",
        "b = np.random.random() * 10\n",
        "sigma = 0.1 + np.random.random() * 10\n",
        "X = np.random.normal(0, sigma, m)\n",
        "Y = X * b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SY2kr6GviwMD",
        "colab_type": "text"
      },
      "source": [
        "* Linear Model\n",
        "\n",
        "  - $h_\\theta(x) = \\theta_0 + \\theta_1 x$, $\\quad$ where $\\theta = (\\theta_0, \\theta_1)$ and $\\theta_0, \\theta_1 \\in \\mathbb{R}$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pNhtCsizq5VK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "theta0 = np.random.random()\n",
        "theta1 = np.random.random()\n",
        "\n",
        "def h(x):\n",
        "  return thera0 + theta1 * x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_ksllqpi00z",
        "colab_type": "text"
      },
      "source": [
        "* Objective Function\n",
        "\n",
        "  - $J(\\theta) = \\frac{1}{2 m} \\sum_{i=1}^m (h_\\theta(x^{(i)}) - y^{(i)})^2$\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24-uZPcCi2Bv",
        "colab_type": "text"
      },
      "source": [
        "* Gradient Descent\n",
        " \n",
        "  - $\\theta_0^{(t+1)} \\colon= \\theta_0^{(t)} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)})$\n",
        "  - $\\theta_1^{(t+1)} \\colon= \\theta_1^{(t)} - \\alpha \\frac{1}{m} \\sum_{i=1}^{m} (h_\\theta(x^{(i)}) - y^{(i)}) x^{(i)}$\n",
        "  - you can choose a step-size (learning rate) $\\alpha > 0`$ in $`\\mathbb{R}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3-ICyxqi7so",
        "colab_type": "text"
      },
      "source": [
        "#### [Plotting the results]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lCASVH2Rermq",
        "colab_type": "text"
      },
      "source": [
        "* Input data [2pt]\n",
        "  - a straight line that is the graph of a linear function (in blue color)\n",
        "  - a set of points that have random perturbations with respect to the straight line (in black color)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9x9Vd-2i98U",
        "colab_type": "text"
      },
      "source": [
        "* Output results [2pt]\n",
        "  - the set of points that have random perturbations with respect to the straight line (in black color)\n",
        "  - a straight line that is the graph of a solution obtained by linear regression (in red color)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1c2I4SPei-on",
        "colab_type": "text"
      },
      "source": [
        "* Plotting the energy values [3pt]\n",
        "  - the value of the objective function at every optimization step by the gradient descent algorithm (in blue color)\n",
        "  - the optimization should be performed until convergence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GBLNmAOi_IG",
        "colab_type": "text"
      },
      "source": [
        "* Plotting the model parameters [3pt]\n",
        "  - the value of the model parameters $\\theta_0$ and $\\theta_1$ at every optimization step (in red ($\\theta_0$) and blue ($\\theta_1$) colors)\n",
        "  - the optimization should be performed until convergence\n"
      ]
    }
  ]
}